{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e653e6-e9d5-4909-a0b1-8f5d95c26e5a",
   "metadata": {},
   "source": [
    "# Modélisation d'une architecture Transformers pour une tâche de génération de texte en anglais/français. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb84f68-e34d-4334-b49a-3a5371b1425a",
   "metadata": {},
   "source": [
    "## Modèle T5 de Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84a1cca0-9a17-4ae4-b7c4-acc35472158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers torch sentencepiece transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6915b9d4-1f68-4667-ad1b-211fd66864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Chargement du modèle et du tokenizer\n",
    "checkpoint = \"t5-base\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint)\n",
    "model = T5ForConditionalGeneration.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60744d4d-8d68-4982-82de-72ae6e849aa6",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42c34e92-1adb-4d3f-8621-f19eeadda289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de prompt\n",
    "prompt_en = \"translate English to French: The weather was nicer yesterday.\"\n",
    "prompt_fr = \"translate French to English: Le temps est agréable aujourd'hui.\"\n",
    "\n",
    "# Tokenisation\n",
    "input_ids_en = tokenizer.encode(prompt_en, return_tensors=\"pt\")\n",
    "input_ids_fr = tokenizer.encode(prompt_fr, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "032d2c38-6c98-4b96-a440-71eba783400f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text (EN to FR): Le temps a été plus agréable hier.\n",
      "Generated Text (FR to EN): Bonjour tout le monde.\n"
     ]
    }
   ],
   "source": [
    "# Génération de texte en anglais vers français\n",
    "output_en = model.generate(input_ids_en)\n",
    "generated_text_en = tokenizer.decode(output_en[0], skip_special_tokens=True)\n",
    "\n",
    "# Génération de texte en français vers anglais\n",
    "output_fr = model.generate(input_ids_fr)\n",
    "generated_text_fr = tokenizer.decode(output_fr[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Text (EN to FR):\", generated_text_en)\n",
    "print(\"Generated Text (FR to EN):\", generated_text_fr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02f3657-6fb9-4085-b433-38897876ee84",
   "metadata": {},
   "source": [
    "##  Évaluation des Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8b0cb1d5-ef2e-495e-896a-6fe78be97e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score (EN to FR): 0.6434588841607617\n",
      "BLEU Score (FR to EN): 0\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Exemple de phrase attendue\n",
    "reference_fr = \"Le temps a été plus qu'agréable hier.\"\n",
    "reference_en = \"The weather is nice today.\"\n",
    "\n",
    "# Calculer le score BLEU\n",
    "bleu_score_fr = sentence_bleu([reference_fr.split()], generated_text_en.split())\n",
    "bleu_score_en = sentence_bleu([reference_en.split()], generated_text_fr.split())\n",
    "\n",
    "print(\"BLEU Score (EN to FR):\", bleu_score_fr)\n",
    "print(\"BLEU Score (FR to EN):\", bleu_score_en)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b8571a-1e92-4c0f-888e-1920381be354",
   "metadata": {},
   "source": [
    "BLEU (Bilingual Evaluation Understudy) : C'est une métrique utilisée pour évaluer la qualité des traductions automatiques. Elle compare la sortie d'un modèle avec une ou plusieurs traductions de référence.\n",
    "1 signifie que notre modèle atraduit bien de l'anglais vers le français mais l'inverse est totalement erroné."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c302f5-75e4-4172-9356-8192c9da23c5",
   "metadata": {},
   "source": [
    "## Model Helsinki du réseau Marian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7f33ac65-c110-44a1-b894-23ce5ac71dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05061c0b8977472cb74ab26498fa446c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Charger le modèle et le tokenizer pour la traduction FR vers EN\n",
    "checkpoint = \"Helsinki-NLP/opus-mt-fr-en\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(checkpoint)\n",
    "model = MarianMTModel.from_pretrained(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82af7508-ed91-4f02-b62d-a4a41651b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de phrase en français\n",
    "sentence_fr = \"Le temps est agréable aujourd'hui.\"\n",
    "\n",
    "# Tokenisation\n",
    "input_ids = tokenizer.encode(sentence_fr, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a69396f-6bcb-407a-a12c-53f5fde616ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Text (FR to EN): The weather is nice today.\n"
     ]
    }
   ],
   "source": [
    "# Génération de texte\n",
    "output = model.generate(input_ids, max_length=40, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Décodage de la sortie\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Translated Text (FR to EN):\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00aac906-8fa0-4680-a73f-02607997d5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score (FR to EN): 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Exemple de phrase attendue en anglais\n",
    "reference_en = \"The weather is nice today.\"\n",
    "\n",
    "# Calculer le score BLEU\n",
    "bleu_score = sentence_bleu([reference_en.split()], generated_text.split())\n",
    "\n",
    "print(\"BLEU Score (FR to EN):\", bleu_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5bb29d-5255-426d-856e-5dba7ad68c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d294500-eeb7-4cff-892c-dadfecd37906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe1d01-8816-43ae-8ebb-98be10f2c809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da270c-a903-41e4-b6af-83e853a8f093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2605b958-1ef5-4ff8-8f19-e2812ecf7412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
